{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to perform AutoML Model Training on Your Data\n",
    "\n",
    "To train the models on your data, follow these four steps:\n",
    "\n",
    "1. **Read the Data**  \n",
    "   Load your dataset for processing and model training.\n",
    "\n",
    "2. **Split the Data into X and y**  \n",
    "   Separate the features (X) and the target variable (y) for training.\n",
    "\n",
    "3. **Specify the Training Config**  \n",
    "   Set up the configuration parameters required for training.\n",
    "\n",
    "4. **Initialize AutoML class and call the `fit` function**  \n",
    "   Pass the training config to the AutoML class and your data to the `fit` function to start the training process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from automl import AutoML\n",
    "\n",
    "# 1. Read the data\n",
    "train_data = pd.read_csv('data/train_titanic.csv')\n",
    "\n",
    "# Split the data into X and y(target)\n",
    "X, y = train_data.drop('Survived', axis=1), train_data['Survived']\n",
    "\n",
    "# 3. Specify your configs according to your needs\n",
    "# example config below\n",
    "configs = {\n",
    "\n",
    "    \"ignore_columns_for_training\": ['Name'],\n",
    "    \"fit_numerical_to_categorical\": ['Pclass'],\n",
    "    \"preproc_steps\": [\n",
    "        {\n",
    "            'step': 'impute',\n",
    "            'method': 'mean',\n",
    "            'columns_to_include': ['Age', 'Fare']\n",
    "        },\n",
    "        {\n",
    "            'step': 'impute',\n",
    "            'method': 'mode',\n",
    "            'columns_to_include': ['Sex', 'Pclass']\n",
    "        },\n",
    "        {\n",
    "            'step': 'encode',\n",
    "            'method': 'one_hot',\n",
    "            'columns_to_include': ['Sex', 'Pclass']\n",
    "        },\n",
    "        {\n",
    "            'step': 'scale',\n",
    "            'method': 'standard',\n",
    "            'columns_to_include': ['Age', 'Fare']\n",
    "        },\n",
    "        {\n",
    "            'step': 'scale',\n",
    "            'method': 'min_max',\n",
    "            'columns_to_include': ['Age', 'Fare']\n",
    "        },\n",
    "        {\n",
    "            'step': 'outlier',\n",
    "            'method': 'robust',\n",
    "            'columns_to_include': ['Age', 'Fare']\n",
    "        },\n",
    "        {\n",
    "            'step': 'skew',\n",
    "            'method': 'yeo_johnson',\n",
    "            'columns_to_include': ['Age', 'Fare']\n",
    "        }\n",
    "    ],\n",
    "\n",
    "    'include_features': 4,\n",
    "    'validation_split_size': 0.5,\n",
    "    'cv_folds': 7,\n",
    "    'task': 'Classification',\n",
    "    'ensemble': False,\n",
    "    'stacking': True,\n",
    "    'tune': True,\n",
    "    'include_models': ['LogisticRegression', 'DecisionTree', 'KNN', 'XGBoost'],\n",
    "    'focus': 'recall',\n",
    "\n",
    "    'experiment_name': 'titanic-experiment'\n",
    "}\n",
    "\n",
    "# 4. Call AutoML fit function\n",
    "# for training the train parameter would be by default True\n",
    "automl = AutoML(configs, train = True)\n",
    "automl.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this check Mlflow to see the logged artifacts and compare the performance of different models.\n",
    "\n",
    "Based on the performance select the model using which you want to do the inference / predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to perform AutoML Inference on Your Data\n",
    "\n",
    "To perform inference, follow these three steps:\n",
    "\n",
    "1. **Read the Data**  \n",
    "   Load your dataset and make sure it has the same data that has been used during training as well.\n",
    "\n",
    "2. **Specify the Inference Config**  \n",
    "   Specify just the experiment name and model name. AutoML fetches the corresponding model artifacts from that and does the inference.\n",
    "\n",
    "4. **Call the AutoML `predict` / `predict_proba` Function**  \n",
    "   Pass the inference config to AutoML class and pass the data to `predict` / `predict_proba` function to do the  inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read the inference data\n",
    "inferenced_data = pd.read_csv('data/test_titanic.csv')\n",
    "\n",
    "# 2. Specify the inference config. For inference these two fields are alone enough. Get these from Mlflow\n",
    "configs = {\n",
    "    \"experiment_name\": \"titanic-experiment\",\n",
    "    \"model_name\": \"logistic \"\n",
    "}\n",
    "\n",
    "# 3. Do the inference. \n",
    "# For inference set the train parameter to False\n",
    "automl = AutoML(configs, train = False)\n",
    "predictions = automl.predict(inferenced_data)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
